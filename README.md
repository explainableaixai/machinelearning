## What is Explainable AI?

Explainable Artificial Intelligence (XAI) methods allow data scientists and other stakeholders to interpret decisions of machine learning models. 
XAI provide us with two types of information, global interpretability or which features of machine learning model are most important for its predictions. And local interpretability or which feature values of a particular instance most influenced the outcome and in what way. 

## Why do we need Explainable Artificial Intelligence?
AI based decision making is being increasingly used in our everyday lives. When we go to an online store the products suggested to us are determined by an AI model - most probably a hybrid of content based and collaborative filtering method. 
The disease diagnosis is another area where AI is also being increasingly used. Another field is finance, where our credit risk is most likely calculated by a machine learning model. 

However, machine learning models are often a black box. To reconcile this with desire and demands of humans to have decisions explained to them a new field has developed within AI area - Explainable Artificial Intelligence or XAI. 

## Who is also driving demand for XAI?
Apart from customers, a key stakeholder that is demanding XAI are regulators. Some of the regulations that have put "Right to Explanation" at the center are: 
- GDPR
- Fair Credit Report Act

Resources: 

[SHAP](https://github.com/slundberg/shap)
[LIME](https://github.com/marcotcr/lime)
[Explainable AI Consulting](https://www.alpha-quantum.com/)
[ELI5](https://github.com/TeamHG-Memex/eli5)
[PDPBOX](https://github.com/SauceCat/PDPbox)


